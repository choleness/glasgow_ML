{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning for Biology\n",
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have used:\n",
    "* **Regression problems**: Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "* **Classification problems**: Classification accuracy (so far)--> there are lots of other ways to evaluate classifiers, and we'll learn them now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get the classification accuracy of a logistic regression fit to the cancer dataset\n",
    "Classification accuracy is the proportion of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer = pd.read_csv(\"data/cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = cancer.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = cancer['diagnosis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Accuracy\n",
    "The accuracy that can be achieved by always predicting the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = class_le.fit_transform(y_test)\n",
    "y_pred = class_le.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.Series(y_test)\n",
    "y_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    66\n",
       "1    48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5789473684210527"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of zeros\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5789473684210527"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.578947\n",
       "dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "Pred: 0     1\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     1\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    1\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    1\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Classification accuracy is the easiest classification metric to understand\n",
    "* But, it does not tell you the underlying distribution of response values\n",
    "* And, it does not tell you what \"types\" of errors your classifier is making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_predictions = dummy_majority.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_predictions = le.fit_transform(dummy_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, dummy_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dummy Classifiers serves as a sanity check for your classifier's performance\n",
    "* They provide a null metric\n",
    "* Dummy Classifiers should not be used for real problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Other commonly-used `strategy` parameters for DummyClassifiers**\n",
    "* `most_frequent`: predicts the most frequent label in the training set\n",
    "* `stratified`: random predictions based on training set distribution\n",
    "* `uniform`: generates predictions uniformly at random\n",
    "* `constant`: always predicts constant label provided by the user (useful for calculating F1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if my classifier accuracy is close to null accuracy?\n",
    "This could be a sign of\n",
    "* ineffective, erroneous, or missing features\n",
    "* poor choice of kernel or hyperparameters\n",
    "* large class imbalance (AUC may be a better score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "Table that describes the performance of a classification model\n",
    "\n",
    "<img src=\"assets/confusionmatrix.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the confusion matrix for the logistic regression of the cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  1]\n",
      " [ 2 46]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every observation in the testing set is represented in exactly one box\n",
    "It's a 2x2 matrix because there are 2 response classes\n",
    "It tallies how many of the two types of correct predictions were made and the two types of incorrect predictions were made.\n",
    "#### Basic terminology\n",
    "\n",
    "* **True Positives (TP):** we correctly predicted that the sample is malignant\n",
    "* **True Negatives (TN):** we correctly predicted that the sample is benign\n",
    "* **False Positives (FP):** we incorrectly predicted that the sample is malignant (a \"Type I error\")\n",
    "* **False Negatives (FN):** we incorrectly predicted that the sample is benign (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "Pred: [1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred.values[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Work\n",
    "Get the confusion matrix from one of the Dummy Classifiers. How does it compare to the model's confusion matrix? \n",
    "\n",
    "\n",
    "**Bonus** Try out a different classifier and get the confusion matrix for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Calculated from the Confusion Matrix\n",
    "<img src=\"assets/confusionmatrixmetrics.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy: ** overall, how often is the classifier correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "* Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02631578947368421\n",
      "0.02631578947368418\n"
     ]
    }
   ],
   "source": [
    "print((FP + FN) / float(TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "* How \"sensitive\" is the classifier to detecting positive instances?\n",
    "* Also known as \"True Positive Rate\" or \"Recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9583333333333334\n",
      "0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FN))\n",
    "print(metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "* How \"specific\" (or \"selective\") is the classifier in predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "print(TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015151515151515152\n"
     ]
    }
   ],
   "source": [
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
    "* How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787234042553191\n",
      "0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FP))\n",
    "print(metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F-1 Score:** combines precision and accuracy \n",
    "\n",
    "2*((precision X recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968421052631579\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98        66\n",
      "          1       0.98      0.96      0.97        48\n",
      "\n",
      "avg / total       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demystifying Precision and Recall\n",
    "<img src=\"assets/precisionrecall.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Recall, Low Precision\n",
    "<img src=\"assets/lowPlowR.png\"/>\n",
    "<img src=\"assets/legen.jpeg\"/>\n",
    "* Let’s say everything inside the solid lines are pictures of actual hot dogs. \n",
    "* Everything within the dotted line is what the model thought was a picture of hot dogs.\n",
    "* Everything in the square is the entire dataset. \n",
    "* True negatives (denoted tn) samples in your data, which you classified as not belonging to your class correctly. Eg. your “hot dog” vs “not hot dog” image classifier correctly classified your image of a car as not being a “hot dog”.\n",
    "* False negatives (denoted fn) samples in your data, which you classified as not belonging to your class, incorrectly. Eg. your “hot dog” vs “not hot dog” image classifier incorrectly classified an image of a messed up “hot dog” as not being a “hot dog”.\n",
    "* True positives (denoted tp) samples in your data, which you classifed as belonging to your class correctly. Eg. your “hot dog” vs “not hot dog” classifier correctly classifies a “hot dog” as being a “hot dog”.\n",
    "* False positives (denoted fp) samples in your data, which you classified as belonging to your class incorrectly. Eg. your “hot dog” vs “not hot dog” classifier incorrectly classifies a hamburger as being a “hot dog”.\n",
    "\n",
    "#### High Recall, Low Precision\n",
    "<img src=\"assets/highRlowP.png\"/>\n",
    "* Our classifier casts a very wide net, catches a lot of fish, but also a lot of other things.\n",
    "* Our classifier thinks a lot of things are “hot dogs”; legs on beaches, fries and whatnot. \n",
    "* However it also thinks a lot of “hot dogs” are “hot dogs”. \n",
    "* So from our set of images we got a lot of images classified as “hot dogs”, many of them was in the set of actual “hot dogs”, however a lot of them were also “not hot dogs”.\n",
    "\n",
    "#### Low Recall, High Precision\n",
    "<img src=\"assets/lowRhighP.png\"/>\n",
    "* Our classifier casts a very small but highly specialized net, does not catch a lot of fish, but there is almost only fish in the net.\n",
    "* Our classifier is very picky, and does not think many things are hot dogs. \n",
    "* All the images it thinks are “hot dogs”, are really “hot dogs”. \n",
    "* However it also misses a lot of actual “hot dogs”, because it is so very picky. \n",
    "\n",
    "#### High Recall, High Precision\n",
    "<img src=\"assets/highRhighP.png\"/>\n",
    "* The holy grail, our fish net is wide and highly specialised. \n",
    "* We catch a lot of fish (almost all of it) and we almost get only fish, nothing else.\n",
    "* Our classifier is very good, it is very picky, but still it gets almost all of the images of “hot dogs” which are “hot dogs” correct. \n",
    "* We are happy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other metrics can be computed as well: F1 score, Matthews correlation coefficient, etc.\n",
    "\n",
    "**Conclusion:**\n",
    "* Confusion matrix gives you a more complete picture of how your classifier is performing\n",
    "* Also allows you to compute various classification metrics, and these metrics can guide your model selection\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "* Choice of metric depends on your objective\n",
    "* Recall-oriented tasks: search and information extraction in legal discovery, tumor detection, tasks paired with human experts to weed out false positives\n",
    "* Precision-oriented tasks: search engine ranking, query suggestions, document classification, many customer-facing tasks (users remember failures)\n",
    "\n",
    "***Which matters more for your research problem?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the classification threshold\n",
    "Like a metal detector being adjusted to look for larger and smaller bits of metal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.67878539e-07, 9.99999532e-01],\n",
       "       [9.89287779e-01, 1.07122213e-02],\n",
       "       [9.95795960e-01, 4.20403993e-03],\n",
       "       [9.84205308e-01, 1.57946922e-02],\n",
       "       [9.27883634e-01, 7.21163663e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [9.51394009e-01, 4.86059910e-02],\n",
       "       [9.98655866e-01, 1.34413373e-03],\n",
       "       [8.46619852e-01, 1.53380148e-01],\n",
       "       [9.95505927e-01, 4.49407305e-03]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row is an observation and \n",
    "# each column is the probability it belongs to that class (add up to 1)\n",
    "logreg.predict_proba(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `.predict` is using these probabilities to choose which class it predicts (if greater than 50%). If we adjust this threshold, we can adjust the sensitivity and specificity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999953, 0.01071222, 0.00420404, 0.01579469, 0.07211637,\n",
       "       1.        , 0.04860599, 0.00134413, 0.15338015, 0.00449407])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities for class 1\n",
    "logreg.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a239e00f0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEZCAYAAACXRVJOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDID/D7PWUVWMIWGMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a237d8cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of predicted probabilities\n",
    "plt.hist(y_pred_prob, bins=8)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decrease the threshold for predicting malignancy to increase the sensitivity of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict malignant if the predicted probability is greater than 0.3\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred = binarize([y_pred_prob], 0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999953, 0.01071222, 0.00420404, 0.01579469, 0.07211637,\n",
       "       1.        , 0.04860599, 0.00134413, 0.15338015, 0.00449407])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities\n",
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted classes with the lower threshold\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  1]\n",
      " [ 2 46]]\n"
     ]
    }
   ],
   "source": [
    "# previous confusion matrix (default threshold of 0.5)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  1]\n",
      " [ 2 46]]\n"
     ]
    }
   ],
   "source": [
    "# new confusion matrix (threshold of 0.3)\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Threshold of 0.5 is used by default (for binary problems) to convert predicted probabilities into class predictions\n",
    "* Threshold can be adjusted to increase sensitivity or specificity\n",
    "* Sensitivity and specificity have an inverse relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Exercise\n",
    "* Calculate the confusion matrix for the diabetes dataset after doing a support vector machine with a kernel of your choice.  \n",
    "* Get the confusion matrix.\n",
    "* Get the metrics from the confusion matrix. \n",
    "* What can you say about the precision and recall of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves and Area Under the Curve (AUC)\n",
    "*Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?*\n",
    "\n",
    "**ROC curves to the rescue!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Receiver Operator Curves** tell us about the false positive and true positive rates. A diagonal line would be the same as random guessing. If the ROC curve falls below the diagonal, it is worse than random guessing. A perfect classifier would fall on the edge of the top left corner (true positive rate of 1, false positive rate of 0). The **Area Under the Curve (AUC)** score tells us about the performance of the model. \n",
    "\n",
    "<img src=\"assets/roc.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the AUC for the cancer dataset\n",
    "AUC is the percentage of the ROC plot that is underneath the curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715909090909092\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_true=y_test, y_score = y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AUC is useful as a single number summary of classifier performance.\n",
    "* If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a higher predicted probability to the positive observation.\n",
    "* AUC is useful even when there is high class imbalance (unlike classification accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23abf240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for cancer classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ROC curve can help you to choose a threshold that balances sensitivity and specificity in a way that makes sense for your particular context\n",
    "* You can't actually see the thresholds used to generate the curve on the ROC curve itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.8958333333333334\n",
      "Specificity: 0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.8958333333333334\n",
      "Specificity: 0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Independent Practice\n",
    "Plot the ROC Curve and calculate the AUC for the diabetes dataset for a classifier of your choice.\n",
    "\n",
    "*What classification accuracy threshold do you recommend?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Confusion matrix advantages:**\n",
    "* Allows you to calculate a variety of metrics\n",
    "* Useful for multi-class problems (more than two response classes)\n",
    "\n",
    "\n",
    "**ROC/AUC advantages:**\n",
    "* Does not require you to set a classification threshold\n",
    "* Still useful when there is high class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other useful things to look at\n",
    "* **Learning/Validation Curves:** how does the evaluation metric change as a function of training data set size? (cost-benefit analysis of getting more data)\n",
    "* **Sensitivity Analysis:** how does the evaluation metric change as a function of key learning parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Independent Work\n",
    "Combine what we learned here about evaluation metrics with what we learned in the hyperparameter tuning lesson.\n",
    "* Fit a classifier of your choice on a dataset of your choice (or use the cancer dataset) using k-fold cross validation and get accuracy, ROC/AUC, and recall.\n",
    "* Using grid search, optimize for best ROC/AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
